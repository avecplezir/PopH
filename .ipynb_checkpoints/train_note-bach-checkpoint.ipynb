{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 8,
>>>>>>> 395527decf2fd675d541e2e95cd03c16156f6bc8
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import argparse\n",
    "import midi\n",
    "import os\n",
    "\n",
    "from constants import *\n",
    "from dataset import *\n",
    "from generate import *\n",
    "from midi_util import midi_encode\n",
    "from model import *\n",
    "from keras import backend as K\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 9,
>>>>>>> 395527decf2fd675d541e2e95cd03c16156f6bc8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 2,
=======
     "execution_count": 9,
>>>>>>> 395527decf2fd675d541e2e95cd03c16156f6bc8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles[0]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 10,
>>>>>>> 395527decf2fd675d541e2e95cd03c16156f6bc8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "train_data, train_labels = load_all(styles, BATCH_SIZE, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 11,
>>>>>>> 395527decf2fd675d541e2e95cd03c16156f6bc8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128, 48, 3)\n",
      "(10, 128, 48, 3)\n",
      "(10, 128, 16)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(train_data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 12,
>>>>>>> 395527decf2fd675d541e2e95cd03c16156f6bc8
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
<<<<<<< HEAD
     "execution_count": 5,
=======
     "execution_count": 12,
>>>>>>> 395527decf2fd675d541e2e95cd03c16156f6bc8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data[2][4]==0).any()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 13,
>>>>>>> 395527decf2fd675d541e2e95cd03c16156f6bc8
   "metadata": {},
   "outputs": [],
   "source": [
    "DENSE_SIZE = 256\n",
    "PROJECTION_DIM = 64\n",
    "N_HEADS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Lambda, Reshape, Permute\n",
    "from keras.layers import TimeDistributed, RepeatVector, Conv1D, Activation\n",
    "from keras.layers import Embedding, Flatten, dot, concatenate \n",
    "from keras.layers.merge import Concatenate, Add, Multiply\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras import losses\n",
    "\n",
    "from util import *\n",
    "from constants import *\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "def primary_loss(y_true, y_pred):\n",
    "    # 3 separate loss calculations based on if note is played or not\n",
    "    played = y_true[:, :, :, 0]\n",
    "    harmony = K.sum(K.reshape(played,(-1,128,12,4)). axis = -1)\n",
    "    bce_note = losses.binary_crossentropy(y_true[:, :, :, 0], y_pred[:, :, :, 0])\n",
    "    bce_replay = losses.binary_crossentropy(y_true[:, :, :, 1], tf.multiply(played, y_pred[:, :, :, 1]) + tf.multiply(1 - played, y_true[:, :, :, 1]))\n",
    "    mse = losses.mean_squared_error(y_true[:, :, :, 2], tf.multiply(played, y_pred[:, :, :, 2]) + tf.multiply(1 - played, y_true[:, :, :, 2]))\n",
    "    return bce_note + bce_replay + mse\n",
    "\n",
    "def pitch_pos_in_f(time_steps):\n",
    "    \"\"\"\n",
    "    Returns a constant containing pitch position of each note\n",
    "    \"\"\"\n",
    "    def f(x):\n",
    "        note_ranges = tf.range(NUM_NOTES, dtype='float32') / NUM_NOTES\n",
    "        repeated_ranges = tf.tile(note_ranges, [tf.shape(x)[0] * time_steps])\n",
    "        return tf.reshape(repeated_ranges, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "    return f\n",
    "\n",
    "def pitch_class_in_f(time_steps):\n",
    "    \"\"\"\n",
    "    Returns a constant containing pitch class of each note\n",
    "    \"\"\"\n",
    "    def f(x):\n",
    "        pitch_class_matrix = np.array([one_hot(n % OCTAVE, OCTAVE) for n in range(NUM_NOTES)])\n",
    "        pitch_class_matrix = tf.constant(pitch_class_matrix, dtype='float32')\n",
    "        pitch_class_matrix = tf.reshape(pitch_class_matrix, [1, 1, NUM_NOTES, OCTAVE])\n",
    "        return tf.tile(pitch_class_matrix, [tf.shape(x)[0], time_steps, 1, 1])\n",
    "    return f\n",
    "\n",
    "def pitch_bins_f(time_steps):\n",
    "    def f(x):\n",
    "        bins = tf.reduce_sum([x[:, :, i::OCTAVE, 0] for i in range(OCTAVE)], axis=3)\n",
    "        bins = tf.tile(bins, [NUM_OCTAVES, 1, 1])\n",
    "        bins = tf.reshape(bins, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "        return bins\n",
    "    return f\n",
    "\n",
    "def time_axis(dropout):\n",
    "    def f(notes, beat):\n",
    "        time_steps = int(notes.get_shape()[1])\n",
    "\n",
    "        # TODO: Experiment with when to apply conv\n",
    "        note_octave = TimeDistributed(Conv1D(OCTAVE_UNITS, 2 * OCTAVE, padding='same'))(notes)\n",
    "        note_octave = Activation('tanh')(note_octave)\n",
    "        note_octave = Dropout(dropout)(note_octave)\n",
    "\n",
    "        # Create features for every single note.\n",
    "        note_features = Concatenate()([\n",
    "            Lambda(pitch_pos_in_f(time_steps))(notes),\n",
    "            Lambda(pitch_class_in_f(time_steps))(notes),\n",
    "            Lambda(pitch_bins_f(time_steps))(notes),\n",
    "            note_octave,\n",
    "            TimeDistributed(RepeatVector(NUM_NOTES))(beat)\n",
    "        ])\n",
    "\n",
    "        x = note_features\n",
    "        # [batch, notes, time, features]\n",
    "        x = Permute((2, 1, 3))(x)\n",
    "\n",
    "        # Apply LSTMs\n",
    "        for l in range(TIME_AXIS_LAYERS):\n",
    "\n",
    "            x = TimeDistributed(LSTM(TIME_AXIS_UNITS, return_sequences=True))(x)\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "        # [batch, time, notes, features]\n",
    "        return Permute((2, 1, 3))(x)\n",
    "    return f\n",
    "\n",
    "def note_axis(dropout):\n",
    "    lstm_layer_cache = {}\n",
    "    note_dense = Dense(2, activation='sigmoid', name='note_dense')\n",
    "    volume_dense = Dense(1, name='volume_dense')\n",
    "\n",
    "    def f(x, chosen):\n",
    "        time_steps = int(x.get_shape()[1])\n",
    "\n",
    "        # Shift target one note to the left.\n",
    "        shift_chosen = Lambda(lambda x: tf.pad(x[:, :, :-1, :], [[0, 0], [0, 0], [1, 0], [0, 0]]))(chosen)\n",
    "\n",
    "        # [batch, time, notes, features + 1]\n",
    "        x = Concatenate(axis=3)([x, shift_chosen])\n",
    "\n",
    "\n",
    "        for l in range(NOTE_AXIS_LAYERS):\n",
    "            if l not in lstm_layer_cache:\n",
    "                lstm_layer_cache[l] = LSTM(NOTE_AXIS_UNITS, return_sequences=True)\n",
    "\n",
    "            x = TimeDistributed(lstm_layer_cache[l])(x)\n",
    "            x = Dropout(dropout)(x)\n",
    "            \n",
    "        #print('x', x.shape)  \n",
    "        #print('nx', note_dense(x).shape)\n",
    "        \n",
    "        return Concatenate()([note_dense(x), volume_dense(x)])\n",
    "    return f\n",
    "\n",
    "def build_models(time_steps=SEQ_LEN, input_dropout=0.2, dropout=0.5):\n",
    "    notes_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "    beat_in = Input((time_steps, NOTES_PER_BAR))\n",
    "    # Target input for conditioning\n",
    "    chosen_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "\n",
    "    # Dropout inputs\n",
    "    notes = Dropout(input_dropout)(notes_in)\n",
    "    beat = Dropout(input_dropout)(beat_in)\n",
    "    chosen = Dropout(input_dropout)(chosen_in)\n",
    "\n",
    "    \"\"\" Time axis \"\"\"\n",
    "    time_out = time_axis(dropout)(notes, beat)\n",
    "\n",
    "    \"\"\" Note Axis & Prediction Layer \"\"\"\n",
    "    naxis = note_axis(dropout)\n",
    "    notes_out = naxis(time_out, chosen)\n",
    "\n",
    "    model = Model([notes_in, chosen_in, beat_in], [notes_out])\n",
    "\n",
    "    if len(K.tensorflow_backend._get_available_gpus())>=2:\n",
    "        model = multi_gpu_model(model)\n",
    "\n",
    "    model.compile(optimizer='nadam', loss=[primary_loss])\n",
    "\n",
    "    \"\"\" Generation Models \"\"\"\n",
    "    time_model = Model([notes_in, beat_in], [time_out])\n",
    "\n",
    "    note_features = Input((1, NUM_NOTES, TIME_AXIS_UNITS), name='note_features')\n",
    "    chosen_gen_in = Input((1, NUM_NOTES, NOTE_UNITS), name='chosen_gen_in')\n",
    "    style_gen_in = Input((1, NUM_STYLES), name='style_in')\n",
    "\n",
    "    # Dropout inputs\n",
    "    chosen_gen = Dropout(input_dropout)(chosen_gen_in)\n",
    "    \n",
    "    note_gen_out = naxis(note_features, chosen_gen)\n",
    "    \n",
    "    note_model = Model([note_features, chosen_gen_in], note_gen_out)\n",
    "\n",
    "    return model, time_model, note_model\n",
    "\n",
    "\n",
    "def build_models_with_attention(time_steps=SEQ_LEN, input_dropout=0.2, dropout=0.5):\n",
    "    notes_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "    beat_in = Input((time_steps, NOTES_PER_BAR))\n",
    "    # Target input for conditioning\n",
    "    chosen_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "\n",
    "    # Dropout inputs\n",
    "    notes = Dropout(input_dropout)(notes_in)\n",
    "    beat = Dropout(input_dropout)(beat_in)\n",
    "    chosen = Dropout(input_dropout)(chosen_in)\n",
    "\n",
    "    \"\"\" Time axis \"\"\"\n",
    "    time_out = time_axis(dropout)(notes, beat)\n",
    "    #print('time_out', time_out.shape)\n",
    "\n",
    "    \"\"\" Note Axis & Prediction Layer \"\"\"\n",
    "    naxis = note_axis_attention(dropout)\n",
    "    notes_out = naxis(time_out)\n",
    "    \n",
    "    model = Model([notes_in, chosen_in, beat_in], [notes_out])\n",
    "\n",
    "    if len(K.tensorflow_backend._get_available_gpus())>=2:\n",
    "        model = multi_gpu_model(model)\n",
    "\n",
    "    model.compile(optimizer='nadam', loss=[primary_loss])\n",
    "    \n",
    "    \"\"\" Generation Models \"\"\"\n",
    "    time_model = Model([notes_in, beat_in], [time_out])\n",
    "\n",
    "    note_features = Input((1, NUM_NOTES, TIME_AXIS_UNITS), name='note_features')\n",
    "    chosen_gen_in = Input((1, NUM_NOTES, NOTE_UNITS), name='chosen_gen_in')\n",
    "   \n",
    "    # Dropout inputs\n",
    "    chosen_gen = Dropout(input_dropout)(chosen_gen_in)\n",
    "    \n",
    "    #print('NUM_NOTES', NUM_NOTES)\n",
    "    note_gen_out = naxis(note_features)\n",
    "    \n",
    "    note_model = Model([note_features, chosen_gen_in], note_gen_out)\n",
    "\n",
    "    return model, time_model, note_model\n",
    "\n",
    "def note_axis_attention(dropout):\n",
    "    note_dense_att = Dense(2, activation='sigmoid', name='note_dense_att')\n",
    "    volume_dense_att = Dense(1, name='volume_dense_att')\n",
    "\n",
    "    def f(x):\n",
    "        x = attention_layer(x, x, True)\n",
    "        #print('x_att', x.shape)\n",
    "        x = Dropout(dropout)(x)\n",
    "        #print('x_drop', x.get_shape)\n",
    "\n",
    "        v = volume_dense_att(x)\n",
    "        \n",
    "        #print('the end')\n",
    "        #print('dense_vol', v.shape)\n",
    "  \n",
    "        return Concatenate(axis=-1)([note_dense_att(x), volume_dense_att(x)])\n",
    "    \n",
    "    return f\n",
    "\n",
    "def OneHeadAttention(a_drop, q_drop, drop_ratio=0.5):\n",
    "        \n",
    "    a_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(a_drop)\n",
    "    q_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(q_drop)\n",
    "    v_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(a_drop)\n",
    "    \n",
    "    a_proj = Dropout(drop_ratio)(a_proj)\n",
    "    q_proj = Dropout(drop_ratio)(q_proj)\n",
    "    v_proj = Dropout(drop_ratio)(v_proj)\n",
    "    #print('a_proj', a_proj.shape)\n",
    "    \n",
    "    #n = Dense(2)(v_proj)\n",
    "    #print('dense_note', n.shape)\n",
    " \n",
    "    \n",
    "    att_input = Lambda(lambda x: tf.matmul(x[0],x[1], transpose_b=True))([q_proj, a_proj])\n",
    "    #print('att_input', att_input.shape)\n",
    "\n",
    "\n",
    "    att_weights = Activation('softmax')(att_input)\n",
    "    v_new = Lambda(lambda x: tf.matmul(x[0],x[1]))([att_weights, v_proj])\n",
    "    #tf.matmul(att_weights, v_proj)\n",
    "    #print('v_new', v_new.get_shape)\n",
    "     \n",
    "    v_new = Multiply()([q_proj, v_new])\n",
    "    \n",
    "    return v_new\n",
    "\n",
    "def MultyHeadAttention(a_drop, q_drop):\n",
    "\n",
    "    Attention_heads = []\n",
    "    for i in range(N_HEADS):\n",
    "        Attention_heads.append(OneHeadAttention(a_drop, q_drop))\n",
    "        \n",
    "    BigHead = concatenate(Attention_heads, axis=-1)\n",
    "    #print('BigHead', BigHead.shape)   \n",
    "\n",
    "    attention_output = Dense(DENSE_SIZE, use_bias=False)(BigHead)\n",
    "    #print('attention_output', attention_output.shape)\n",
    "\n",
    "           \n",
    "    return attention_output\n",
    "    \n",
    "def attention_layer(a_drop, q_drop, FF):\n",
    "    \n",
    "    #print('a_drop', a_drop.shape)\n",
    "    res = MultyHeadAttention(a_drop, q_drop)\n",
    "    #print('res', res.shape)\n",
    "        \n",
    "    att = Add()([a_drop, res])\n",
    "    #att = normalize()(att)    \n",
    " \n",
    "    #Feed Forward\n",
    "    if FF:\n",
    "        att_ff = Dense(DENSE_SIZE*4, activation = 'relu')(att)\n",
    "        att_ff = Dense(DENSE_SIZE)(att_ff)   \n",
    "        att_ff = Dropout(0.1)(att_ff)\n",
    "        att_add = Add()([att, att_ff])\n",
    "        #att = normalize()(att_add) \n",
    "    \n",
    "    return att\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DENSE_SIZE, PROJECTION_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"loss_31/concatenate_159_loss/Min:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "models = build_models_with_attention(time_steps=SEQ_LEN, \n",
    "                                     input_dropout=0.2, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 94,
=======
   "execution_count": 14,
>>>>>>> 395527decf2fd675d541e2e95cd03c16156f6bc8
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
<<<<<<< HEAD
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/4\n",
      "9/9 [==============================] - 24s 3s/step - loss: 0.1209 - val_loss: 0.0347\n",
      "Epoch 2/4\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 3/4\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 4/4\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.0025 - val_loss: 0.0043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ba7affd0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
=======
      "Train on 323 samples, validate on 17 samples\n",
      "Epoch 1/1\n",
      " 68/323 [=====>........................] - ETA: 2:28 - loss: 0.3061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-63acfe02e6db>\", line 9, in <module>\n",
      "    epochs=1, callbacks=cbs, batch_size=1)\n",
      "  File \"/home/egor/.local/lib/python3.5/site-packages/keras/engine/training.py\", line 1705, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/home/egor/.local/lib/python3.5/site-packages/keras/engine/training.py\", line 1235, in _fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/home/egor/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2478, in __call__\n",
      "    **self.session_kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 789, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 997, in _run\n",
      "    feed_dict_string, options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1132, in _do_run\n",
      "    target_list, options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1139, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1121, in _run_fn\n",
      "    status, run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 718, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.5/posixpath.py\", line 372, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.5/posixpath.py\", line 406, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/lib/python3.5/posixpath.py\", line 161, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
>>>>>>> 395527decf2fd675d541e2e95cd03c16156f6bc8
    }
   ],
   "source": [
    "cbs = [\n",
    "    ModelCheckpoint(MODEL_FILE, monitor='loss', save_best_only=True, save_weights_only=True),\n",
    "    EarlyStopping(monitor='loss', patience=5),\n",
    "    #TensorBoard(log_dir='out/logs', histogram_freq=1)\n",
    "]\n",
    "\n",
    "print('Training')\n",
    "models[0].fit(train_data, train_labels, validation_split=0.05,\n",
    "              epochs=4, callbacks=cbs, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:24<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/bach_self12_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# models = build_models()\n",
    "# models = build_models_with_attention(time_steps=SEQ_LEN, \n",
    "#                                      input_dropout=0.2, dropout=0.5)\n",
    "# models[0].load_weights(os.path.join(OUT_DIR, 'model.h5'))\n",
    "write_file('output/bach_self12', generate(models, 4, Attention = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = build_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/4\n",
      "9/9 [==============================] - 22s 2s/step - loss: 0.2668 - val_loss: 0.2061\n",
      "Epoch 2/4\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1248 - val_loss: 0.2147\n",
      "Epoch 3/4\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.1201 - val_loss: 0.1833\n",
      "Epoch 4/4\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.1161 - val_loss: 0.1879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18966bdba8>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbs = [\n",
    "    ModelCheckpoint(MODEL_FILE, monitor='loss', save_best_only=True, save_weights_only=True),\n",
    "    EarlyStopping(monitor='loss', patience=5),\n",
    "    #TensorBoard(log_dir='out/logs', histogram_freq=1)\n",
    "]\n",
    "\n",
    "print('Training')\n",
    "models[0].fit(train_data, train_labels, validation_split=0.05,\n",
    "              epochs=4, callbacks=cbs, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:00<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/bach3_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# models = build_models()\n",
    "# models = build_models_with_attention(time_steps=SEQ_LEN, \n",
    "#                                      input_dropout=0.2, dropout=0.5)\n",
    "# models[0].load_weights(os.path.join(OUT_DIR, 'model.h5'))\n",
    "write_file('output/bach3', generate(models, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (?, 128, 48, 128)\n",
      "nx (?, 128, 48, 2)\n",
      "x (?, 1, 48, 128)\n",
      "nx (?, 1, 48, 2)\n"
     ]
    }
   ],
   "source": [
    "models = build_models(time_steps=SEQ_LEN, input_dropout=0.2, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(SAMPLES_DIR, 'encode_decoded_song' + '_' + str(i) + '.mid')\n",
    "pattern = midi.read_midifile('data/Bach1/Toccata & Fuga in F-Dur, BWV 540.mid')\n",
    "result = midi_decode(pattern)\n",
    "mf = midi_encode(unclamp_midi(clamp_midi(result)))\n",
    "midi.write_midifile(fpath, mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.array([[np.ones((2,3)), np.eye(3)[:2]]])\n",
    "# A = K.variable(A)\n",
    "# print(K.eval(A))\n",
    "# print(A.shape)\n",
    "# # x = Dense(4, kernel_initializer='Ones')(A)\\\n",
    "# print('slice x', K.eval(A[:, :, :-1, :]))\n",
    "\n",
    "# x = Lambda(lambda x: tf.pad(x[:, :, :-1, :], \n",
    "#                         [[0, 0], [0, 0], [1, 0], [0, 0]]))(A)\n",
    "\n",
    "# print(x.shape)\n",
    "# print('x', K.eval(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models[0].save_weights(os.path.join(OUT_DIR, 'raw_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = build_models()\n",
    "# models[0].load_weights(MODEL_FILE)\n",
    "# write_file('output2', generate(models, 4, styles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_beat(3, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = deque([np.zeros((2, 3)) for _ in range(2)], maxlen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([array([[0., 0., 0.],\n",
       "              [0., 0., 0.]]), array([[0., 0., 0.],\n",
       "              [0., 0., 0.]])])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.append(np.ones((2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([array([[1., 1., 1.],\n",
       "              [1., 1., 1.]]), array([[1., 1., 1.],\n",
       "              [1., 1., 1.]])])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOTES_PER_BAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i, result in enumerate(generate(models, 4, styles)):\n",
    "# #     print(i)\n",
    "# #     print(np.array(result).shape)\n",
    "# #     print(unclamp_midi(result).shape)\n",
    "# #     print(midi_encode(unclamp_midi(result)))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = MusicGeneration(styles[0])\n",
    "a = g.build_time_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 48, 3)\n",
      "(128, 16)\n",
      "(128, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[0]==0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[1]==0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 48, 3)\n",
      "(1, 128, 16)\n",
      "(1, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in process_inputs([a]):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 48, 256)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].predict(process_inputs([a]))[:, -1:, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 256)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_features = models[1].predict(process_inputs([a]))[:, -1:, :]\n",
    "note_features[0, : ,: , :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 256)\n",
      "(1, 48, 3)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "b = g.build_note_inputs(note_features[0, : ,: , :])\n",
    "for i in b:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 48, 256)\n",
      "(1, 1, 48, 3)\n",
      "(1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in process_inputs([b]):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 48, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = np.array(models[2].predict(process_inputs([b])))\n",
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr2 = pr[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0836291"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr2[2, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = apply_temperature(pr2[2, :-1], g.temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49578953, 0.4675863 ], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.choose(pr[0][-1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
